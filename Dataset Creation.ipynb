{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook contains code for dataset creation.\n",
    "\n",
    "### Contributors: Developed by Gökalp Özer, Mete Mert Birdal and Abdullah Palaz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import time\n",
    "import os\n",
    "from os import path\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import csv\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "import keras\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zjvdVd02Axj-"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C_USA4sTAxom"
   },
   "outputs": [],
   "source": [
    "header = 'song_name chroma_stft rmse spectral_centroid spectral_bandwidth rolloff zero_crossing_rate'\n",
    "for i in range(1, 21):\n",
    "    header += f' mfcc{i}'\n",
    "header += \" polarity\"\n",
    "header = header.split()\n",
    "header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jzTrwx-3Axq2"
   },
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3f7wzJEsA3gl"
   },
   "outputs": [],
   "source": [
    "def polarity(lyric):\n",
    "    if(sid.polarity_scores(lyric)['pos'] - sid.polarity_scores(lyric)['neg'] > 0.05 ):\n",
    "        return(1)\n",
    "    else:\n",
    "        return(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i2B3W00rA3jG"
   },
   "outputs": [],
   "source": [
    "for fldr in os.listdir('dataset'):\n",
    "    print(fldr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fq_OdWcqA3nW"
   },
   "outputs": [],
   "source": [
    "sayac = 1\n",
    "for folder_name in os.listdir('dataset')[12:]:\n",
    "    onlyfiles = [f for f in listdir(\"dataset/\" + folder_name) if isfile(join(\"dataset/\" + folder_name, f))]\n",
    "    onlyfiles.sort(key=lambda v: v.upper())\n",
    "    matching = [s for s in onlyfiles if \"lyrics.csv\" in s]\n",
    "    onlyfiles.remove(matching[0])\n",
    "    lyrics = pd.read_csv(\"dataset/\" + folder_name + \"/\" + matching[0], index_col=False, header=None)\n",
    "    soz_sayaci = 0\n",
    "    for song_name in onlyfiles:\n",
    "        y, sr = librosa.load(glob.glob('dataset/' + folder_name + \"/\" + song_name)[0], duration=90)  \n",
    "    \n",
    "        chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "        rmse = librosa.feature.rms(y=y)\n",
    "        spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "        spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "        rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "        zcr = librosa.feature.zero_crossing_rate(y)\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
    "        to_append = f'{np.mean(chroma_stft)} {np.mean(rmse)} {np.mean(spec_cent)} {np.mean(spec_bw)} {np.mean(rolloff)} {np.mean(zcr)}'\n",
    "        if(type(lyrics[0].values[soz_sayaci]) == float):\n",
    "            sentiment = 0\n",
    "        else:\n",
    "            sentiment = polarity(lyrics[0].values[soz_sayaci])\n",
    "        for e in mfcc:\n",
    "            to_append += f' {np.mean(e)}'\n",
    "        file1 = open('data.csv', 'a', newline='')\n",
    "        with file1:\n",
    "            writer = csv.writer(file1)\n",
    "            writer.writerow([song_name] + to_append.split() + [sentiment])\n",
    "\n",
    "\n",
    "        print(\"BİTTİ\", sayac)\n",
    "        sayac += 1\n",
    "        soz_sayaci +=1\n",
    "\n",
    "    \n",
    "file1.close()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Feature_Extraction_and_Saving_To_a_CSV_File.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
